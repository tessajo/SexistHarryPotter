{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\r\n",
    "import nltk\r\n",
    "import string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.util import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "punct = ['“','”','–','’','‘','—']\r\n",
    "# Statistischee Analysen gesamter Text\r\n",
    "with open(os.path.join('Data','REFINED','master.txt'),'r',encoding='utf-8') as f:\r\n",
    "    content = f.read()\r\n",
    "# print(sents)# Anzahl Sätze\r\n",
    "sents = nltk.sent_tokenize(content)\r\n",
    "amSents = len(sents)\r\n",
    "# Anzahl Worte\r\n",
    "words = nltk.word_tokenize(content)\r\n",
    "amWords = len(words)\r\n",
    "# Durchschnittliche Anzahl Worte / Satz\r\n",
    "avgWordsperSents = amWords/amSents\r\n",
    "print('Durschnittliche Anzahl Worte pro Satz',avgWordsperSents,'\\nAnzahl Worte gesamt',amWords,'\\nAnzahl Sätze gesamt',amSents)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Durschnittliche Anzahl Worte pro Satz 22.517805598165832 \n",
      "Anzahl Worte gesamt 1365187 \n",
      "Anzahl Sätze gesamt 60627\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Stopwörter entfernen\r\n",
    "stop_words = set(stopwords.words('english'))\r\n",
    "\r\n",
    "# n-Grame initialisieren\r\n",
    "unigram = [] # nur das wort wird beachtet\r\n",
    "bigram = [] # Kontext (2 Worte) wird beachtet\r\n",
    "trigram = []\r\n",
    "fourgram = []\r\n",
    "fivegram = []\r\n",
    "sixgram = []\r\n",
    "# tengram = []\r\n",
    "# Tokenisierter Text\r\n",
    "toktext = []\r\n",
    "\r\n",
    "# Satz für Satz evaluieren\r\n",
    "for sentence in sents:\r\n",
    "    sentence = ''.join([char for char in sentence if (char not in string.punctuation) and (char not in punct)])\r\n",
    "    sentence = sentence.lower()\r\n",
    "    sequence = nltk.word_tokenize(sentence)\r\n",
    "    for word in sequence:\r\n",
    "        unigram.append(word)\r\n",
    "    toktext.append(sequence)\r\n",
    "# Stopworte entfernen \r\n",
    "unigram = [p for p in unigram if p not in stop_words]\r\n",
    "# n-Grame erstellen \r\n",
    "bigram.extend(list(ngrams(unigram, 2)))\r\n",
    "trigram.extend(list(ngrams(unigram, 3)))\r\n",
    "fourgram.extend(list(ngrams(unigram, 4)))\r\n",
    "fivegram.extend(list(ngrams(unigram, 5)))\r\n",
    "sixgram.extend(list(ngrams(unigram, 6)))\r\n",
    "# tengram.extend(list(ngrams(unigram, 10)))\r\n",
    "\r\n",
    "def removal(x):\r\n",
    "    res = []\r\n",
    "    for pair in x:\r\n",
    "        count = 0\r\n",
    "        for word in pair:\r\n",
    "            if word in stop_words:\r\n",
    "                count = count or 0\r\n",
    "            else:\r\n",
    "                count = count or 1\r\n",
    "        if (count)==1:\r\n",
    "            res.append(pair)\r\n",
    "    return res\r\n",
    "\r\n",
    "bigram = removal(bigram)\r\n",
    "trigram = removal(trigram)\r\n",
    "fourgram = removal(fourgram)\r\n",
    "fourgram = removal(fivegram)\r\n",
    "fourgram = removal(sixgram)\r\n",
    "# tengram = removal(tengram)\r\n",
    "\r\n",
    "freq_bi = nltk.FreqDist(bigram)\r\n",
    "freq_tri = nltk.FreqDist(trigram)\r\n",
    "freq_four = nltk.FreqDist(fourgram)\r\n",
    "freq_five = nltk.FreqDist(fivegram)\r\n",
    "freq_six = nltk.FreqDist(sixgram)\r\n",
    "# freq_ten = nltk.FreqDist(tengram)\r\n",
    "\r\n",
    "print('freq_bi',freq_bi.most_common(20),'\\n')\r\n",
    "print('freq_tri',freq_tri.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_four.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_five.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_six.most_common(20),'\\n')\r\n",
    "# print('freq_ten',freq_ten.most_common(20),'\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "freq_bi [(('said', 'harry'), 2731), (('said', 'ron'), 1563), (('said', 'hermione'), 1287), (('said', 'dumbledore'), 668), (('mrs', 'weasley'), 604), (('professor', 'mcgonagall'), 600), (('mr', 'weasley'), 569), (('harry', 'could'), 565), (('death', 'eater'), 517), (('ron', 'hermione'), 511), (('harry', 'potter'), 472), (('harry', 'hermione'), 455), (('said', 'hagrid'), 391), (('uncle', 'vernon'), 388), (('fred', 'george'), 379), (('harry', 'said'), 366), (('harry', 'ron'), 361), (('said', 'professor'), 331), (('harry', 'oked'), 329), (('harry', 'id'), 325)] \n",
      "\n",
      "freq_tri [(('said', 'mr', 'weasley'), 198), (('said', 'professor', 'mcgonagall'), 172), (('said', 'mrs', 'weasley'), 152), (('harry', 'could', 'see'), 113), (('yeah', 'said', 'harry'), 111), (('yes', 'said', 'harry'), 83), (('harry', 'could', 'nt'), 78), (('said', 'ron', 'looking'), 73), (('right', 'said', 'harry'), 73), (('harry', 'potter', 'ed'), 69), (('nearly', 'headless', 'nick'), 69), (('said', 'hermione', 'looking'), 68), (('harry', 'oked', 'around'), 66), (('defence', 'dark', 'arts'), 66), (('said', 'harry', 'ickly'), 64), (('said', 'uncle', 'vernon'), 64), (('harry', 'said', 'hermione'), 62), (('defense', 'dark', 'arts'), 58), (('harry', 'could', 'tell'), 51), (('harry', 'could', 'hear'), 49)] \n",
      "\n",
      "freq_four [(('uncle', 'vernon', 'aunt', 'petunia'), 23), (('said', 'nearly', 'headless', 'nick'), 22), (('hogwarts', 'school', 'witchcraft', 'wizardry'), 19), (('said', 'harry', 'potter', 'ly'), 19), (('number', 'twelve', 'grimmauld', 'place'), 16), (('harry', 'said', 'mr', 'weasley'), 15), (('potter', 'said', 'professor', 'mcgonagall'), 15), (('number', 'four', 'privet', 'drive'), 14), (('defense', 'dark', 'arts', 'teacher'), 14), (('said', 'harry', 'ron', 'together'), 13), (('harry', 'could', 'nt', 'help'), 12), (('standard', 'book', 'spells', 'grade'), 12), (('department', 'regulation', 'control', 'magical'), 11), (('regulation', 'control', 'magical', 'creatures'), 11), (('department', 'magical', 'law', 'enforcement'), 11), (('aunt', 'petunia', 'uncle', 'vernon'), 10), (('cornelius', 'fudge', 'minister', 'magic'), 10), (('oh', 'yeah', 'said', 'harry'), 10), (('never', 'mind', 'said', 'harry'), 9), (('could', 'say', 'another', 'word'), 9)] \n",
      "\n",
      "freq_ten [(('sincerely', 'mafalda', 'hopkirk', 'improper', 'use', 'magic', 'office', 'ministry', 'magic', 'harry'), 3), (('dumbledore', 'particularly', 'famous', 'defeat', 'dark', 'wizard', 'grindelwald', '1945', 'discovery', 'twelve'), 2), (('particularly', 'famous', 'defeat', 'dark', 'wizard', 'grindelwald', '1945', 'discovery', 'twelve', 'uses'), 2), (('famous', 'defeat', 'dark', 'wizard', 'grindelwald', '1945', 'discovery', 'twelve', 'uses', 'dragons'), 2), (('defeat', 'dark', 'wizard', 'grindelwald', '1945', 'discovery', 'twelve', 'uses', 'dragons', 'blood'), 2), (('dark', 'wizard', 'grindelwald', '1945', 'discovery', 'twelve', 'uses', 'dragons', 'blood', 'work'), 2), (('wizard', 'grindelwald', '1945', 'discovery', 'twelve', 'uses', 'dragons', 'blood', 'work', 'alchemy'), 2), (('grindelwald', '1945', 'discovery', 'twelve', 'uses', 'dragons', 'blood', 'work', 'alchemy', 'partner'), 2), (('1945', 'discovery', 'twelve', 'uses', 'dragons', 'blood', 'work', 'alchemy', 'partner', 'nicolas'), 2), (('discovery', 'twelve', 'uses', 'dragons', 'blood', 'work', 'alchemy', 'partner', 'nicolas', 'flamel'), 2), (('gilderoy', 'lockhart', 'order', 'merlin', 'third', 'class', 'honorary', 'member', 'dark', 'force'), 2), (('lockhart', 'order', 'merlin', 'third', 'class', 'honorary', 'member', 'dark', 'force', 'defense'), 2), (('order', 'merlin', 'third', 'class', 'honorary', 'member', 'dark', 'force', 'defense', 'league'), 2), (('merlin', 'third', 'class', 'honorary', 'member', 'dark', 'force', 'defense', 'league', 'five\\u200btime'), 2), (('third', 'class', 'honorary', 'member', 'dark', 'force', 'defense', 'league', 'five\\u200btime', 'winner'), 2), (('class', 'honorary', 'member', 'dark', 'force', 'defense', 'league', 'five\\u200btime', 'winner', 'witch'), 2), (('honorary', 'member', 'dark', 'force', 'defense', 'league', 'five\\u200btime', 'winner', 'witch', 'weeklys'), 2), (('member', 'dark', 'force', 'defense', 'league', 'five\\u200btime', 'winner', 'witch', 'weeklys', 'charming'), 2), (('dark', 'force', 'defense', 'league', 'five\\u200btime', 'winner', 'witch', 'weeklys', 'charming', 'smile'), 2), (('force', 'defense', 'league', 'five\\u200btime', 'winner', 'witch', 'weeklys', 'charming', 'smile', 'award'), 2)] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}