{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\r\n",
    "import nltk, string\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.util import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "punct = ['“','”','–','’','‘','—']\r\n",
    "# Statistischee Analysen gesamter Text\r\n",
    "with open(os.path.join('Data','RESULTS','sentenceswithnames.txt'),'r',encoding='utf-8') as f:\r\n",
    "    content = f.read()\r\n",
    "# Anzahl Sätze\r\n",
    "sents = nltk.sent_tokenize(content)\r\n",
    "amSents = len(sents)\r\n",
    "# Anzahl Worte\r\n",
    "words = nltk.word_tokenize(content)\r\n",
    "amWords = len(words)\r\n",
    "# Durchschnittliche Anzahl Worte / Satz\r\n",
    "avgWordsperSents = amWords/amSents\r\n",
    "print('Durschnittliche Anzahl Worte pro Satz',avgWordsperSents,'\\nAnzahl Worte gesamt',amWords,'\\nAnzahl Sätze gesamt',amSents)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Durschnittliche Anzahl Worte pro Satz 50.820419325433 \n",
      "Anzahl Worte gesamt 55750 \n",
      "Anzahl Sätze gesamt 1097\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Stopwörter entfernen\r\n",
    "stop_words = set(stopwords.words('english'))\r\n",
    "\r\n",
    "# n-Grame initialisieren\r\n",
    "unigram = [] # nur das wort wird beachtet\r\n",
    "bigram = [] # Kontext (2 Worte) wird beachtet\r\n",
    "trigram = []\r\n",
    "fourgram = []\r\n",
    "fivegram = []\r\n",
    "sixgram = []\r\n",
    "# tengram = []\r\n",
    "# Tokenisierter Text\r\n",
    "toktext = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# removal-Funktion definieren\r\n",
    "def removal(x):\r\n",
    "    res = []\r\n",
    "    for pair in x:\r\n",
    "        count = 0\r\n",
    "        for word in pair:\r\n",
    "            if word in stop_words:\r\n",
    "                count = count or 0\r\n",
    "            else:\r\n",
    "                count = count or 1\r\n",
    "        if (count)==1:\r\n",
    "            res.append(pair)\r\n",
    "    return res\r\n",
    "# ngram-Funktion definieren\r\n",
    "def calcngram(sents,exceptions):\r\n",
    "    for sentence in sents:\r\n",
    "        sentence = ''.join([char for char in sentence if (char not in string.punctuation) and (char not in punct)])\r\n",
    "        sentence = sentence.lower()\r\n",
    "        sequence = nltk.word_tokenize(sentence)\r\n",
    "        # POS Tags ermitteln\r\n",
    "        pos = nltk.pos_tag(sequence)\r\n",
    "        for word in sequence and word not in exceptions:\r\n",
    "            unigram.append(word)\r\n",
    "        toktext.append(sequence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Satz für Satz evaluieren\r\n",
    "for sentence in sents:\r\n",
    "    sentence = ''.join([char for char in sentence if (char not in string.punctuation) and (char not in punct)])\r\n",
    "    sentence = sentence.lower()\r\n",
    "    sequence = nltk.word_tokenize(sentence)\r\n",
    "    for word in sequence:\r\n",
    "        unigram.append(word)\r\n",
    "    toktext.append(sequence)\r\n",
    "# Stopworte entfernen \r\n",
    "unigram = [p for p in unigram if p not in stop_words]\r\n",
    "\r\n",
    "# n-Grame erstellen \r\n",
    "bigram.extend(list(ngrams(unigram, 2)))\r\n",
    "trigram.extend(list(ngrams(unigram, 3)))\r\n",
    "fourgram.extend(list(ngrams(unigram, 4)))\r\n",
    "fivegram.extend(list(ngrams(unigram, 5)))\r\n",
    "sixgram.extend(list(ngrams(unigram, 6)))\r\n",
    "# tengram.extend(list(ngrams(unigram, 10)))\r\n",
    "\r\n",
    "bigram = removal(bigram)\r\n",
    "trigram = removal(trigram)\r\n",
    "fourgram = removal(fourgram)\r\n",
    "fourgram = removal(fivegram)\r\n",
    "fourgram = removal(sixgram)\r\n",
    "# tengram = removal(tengram)\r\n",
    "\r\n",
    "freq_bi = nltk.FreqDist(bigram)\r\n",
    "freq_tri = nltk.FreqDist(trigram)\r\n",
    "freq_four = nltk.FreqDist(fourgram)\r\n",
    "freq_five = nltk.FreqDist(fivegram)\r\n",
    "freq_six = nltk.FreqDist(sixgram)\r\n",
    "# freq_ten = nltk.FreqDist(tengram)\r\n",
    "\r\n",
    "print('freq_bi',freq_bi.most_common(20),'\\n')\r\n",
    "print('freq_tri',freq_tri.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_four.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_five.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_six.most_common(20),'\\n')\r\n",
    "# print('freq_ten',freq_ten.most_common(20),'\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "freq_bi [(('said', 'harry'), 144), (('harry', 'never'), 78), (('harry', 'could'), 52), (('never', 'seen'), 43), (('harry', 'potter'), 34), (('death', 'eater'), 29), (('harry', 'felt'), 26), (('would', 'never'), 25), (('harry', 'ho'), 25), (('harry', 'knew'), 25), (('harry', 'w'), 25), (('harry', 'said'), 24), (('harry', 'hermione'), 23), (('ron', 'hermione'), 22), (('harry', 'oked'), 22), (('mr', 'weasley'), 22), (('could', 'see'), 22), (('said', 'dumbledore'), 20), (('said', 'hermione'), 19), (('never', 'heard'), 19)] \n",
      "\n",
      "freq_tri [(('harry', 'never', 'seen'), 26), (('harry', 'could', 'see'), 11), (('harry', 'could', 'nt'), 9), (('harry', 'never', 'heard'), 9), (('said', 'mr', 'weasley'), 8), (('defence', 'dark', 'arts'), 7), (('harry', 'oked', 'around'), 7), (('right', 'said', 'harry'), 6), (('said', 'harry', 'nd'), 6), (('said', 'harry', 'ho'), 5), (('knew', 'would', 'never'), 5), (('harry', 'could', 'tell'), 5), (('harry', 'said', 'hermione'), 5), (('harry', 'could', 'hear'), 4), (('never', 'seen', 'anything'), 4), (('thanks', 'said', 'harry'), 4), (('dark', 'arts', 'teacher'), 4), (('harry', 'ever', 'seen'), 4), (('yeah', 'said', 'harry'), 4), (('sir', 'said', 'harry'), 4)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'turned', 'dark', 'witches', 'wizards'), 2), (('oh', 'simple', 'enough', 'anti\\u200bjinx', 'said', 'mr'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'said', 'mr', 'weasley'), 2), (('enough', 'anti\\u200bjinx', 'said', 'mr', 'weasley', 'mounted'), 2), (('anti\\u200bjinx', 'said', 'mr', 'weasley', 'mounted', 'stairs'), 2), (('said', 'mr', 'weasley', 'mounted', 'stairs', 'much'), 2), (('mr', 'weasley', 'mounted', 'stairs', 'much', 'repair'), 2), (('weasley', 'mounted', 'stairs', 'much', 'repair', 'damage'), 2), (('mounted', 'stairs', 'much', 'repair', 'damage', 'attitude'), 2), (('stairs', 'much', 'repair', 'damage', 'attitude', 'behind'), 2), (('much', 'repair', 'damage', 'attitude', 'behind', 'vandalism'), 2), (('repair', 'damage', 'attitude', 'behind', 'vandalism', 'harry'), 2), (('damage', 'attitude', 'behind', 'vandalism', 'harry', 'uggle\\u200bbaiting'), 2), (('attitude', 'behind', 'vandalism', 'harry', 'uggle\\u200bbaiting', 'might'), 2), (('behind', 'vandalism', 'harry', 'uggle\\u200bbaiting', 'might', 'strike'), 2), (('vandalism', 'harry', 'uggle\\u200bbaiting', 'might', 'strike', 'wizards'), 2), (('harry', 'uggle\\u200bbaiting', 'might', 'strike', 'wizards', 'funny'), 2), (('uggle\\u200bbaiting', 'might', 'strike', 'wizards', 'funny', 'expression'), 2), (('might', 'strike', 'wizards', 'funny', 'expression', 'something'), 2), (('strike', 'wizards', 'funny', 'expression', 'something', 'much'), 2)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'turned', 'dark', 'witches'), 2), (('house', 'turned', 'dark', 'witches', 'wizards'), 2), (('oh', 'simple', 'enough', 'anti\\u200bjinx', 'said'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'said', 'mr'), 2), (('enough', 'anti\\u200bjinx', 'said', 'mr', 'weasley'), 2), (('anti\\u200bjinx', 'said', 'mr', 'weasley', 'mounted'), 2), (('said', 'mr', 'weasley', 'mounted', 'stairs'), 2), (('mr', 'weasley', 'mounted', 'stairs', 'much'), 2), (('weasley', 'mounted', 'stairs', 'much', 'repair'), 2), (('mounted', 'stairs', 'much', 'repair', 'damage'), 2), (('stairs', 'much', 'repair', 'damage', 'attitude'), 2), (('much', 'repair', 'damage', 'attitude', 'behind'), 2), (('repair', 'damage', 'attitude', 'behind', 'vandalism'), 2), (('damage', 'attitude', 'behind', 'vandalism', 'harry'), 2), (('attitude', 'behind', 'vandalism', 'harry', 'uggle\\u200bbaiting'), 2), (('behind', 'vandalism', 'harry', 'uggle\\u200bbaiting', 'might'), 2), (('vandalism', 'harry', 'uggle\\u200bbaiting', 'might', 'strike'), 2), (('harry', 'uggle\\u200bbaiting', 'might', 'strike', 'wizards'), 2), (('uggle\\u200bbaiting', 'might', 'strike', 'wizards', 'funny'), 2), (('might', 'strike', 'wizards', 'funny', 'expression'), 2)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'turned', 'dark', 'witches', 'wizards'), 2), (('oh', 'simple', 'enough', 'anti\\u200bjinx', 'said', 'mr'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'said', 'mr', 'weasley'), 2), (('enough', 'anti\\u200bjinx', 'said', 'mr', 'weasley', 'mounted'), 2), (('anti\\u200bjinx', 'said', 'mr', 'weasley', 'mounted', 'stairs'), 2), (('said', 'mr', 'weasley', 'mounted', 'stairs', 'much'), 2), (('mr', 'weasley', 'mounted', 'stairs', 'much', 'repair'), 2), (('weasley', 'mounted', 'stairs', 'much', 'repair', 'damage'), 2), (('mounted', 'stairs', 'much', 'repair', 'damage', 'attitude'), 2), (('stairs', 'much', 'repair', 'damage', 'attitude', 'behind'), 2), (('much', 'repair', 'damage', 'attitude', 'behind', 'vandalism'), 2), (('repair', 'damage', 'attitude', 'behind', 'vandalism', 'harry'), 2), (('damage', 'attitude', 'behind', 'vandalism', 'harry', 'uggle\\u200bbaiting'), 2), (('attitude', 'behind', 'vandalism', 'harry', 'uggle\\u200bbaiting', 'might'), 2), (('behind', 'vandalism', 'harry', 'uggle\\u200bbaiting', 'might', 'strike'), 2), (('vandalism', 'harry', 'uggle\\u200bbaiting', 'might', 'strike', 'wizards'), 2), (('harry', 'uggle\\u200bbaiting', 'might', 'strike', 'wizards', 'funny'), 2), (('uggle\\u200bbaiting', 'might', 'strike', 'wizards', 'funny', 'expression'), 2), (('might', 'strike', 'wizards', 'funny', 'expression', 'something'), 2), (('strike', 'wizards', 'funny', 'expression', 'something', 'much'), 2)] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# n-Grame neu initialisieren\r\n",
    "unigram = [] # nur das wort wird beachtet\r\n",
    "bigram = [] # Kontext (2 Worte) wird beachtet\r\n",
    "trigram = []\r\n",
    "fourgram = []\r\n",
    "fivegram = []\r\n",
    "sixgram = []\r\n",
    "# tengram = []\r\n",
    "# Tokenisierter Text\r\n",
    "toktext = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for sentence in sents:\r\n",
    "    sentence = ''.join([char for char in sentence if (char not in string.punctuation) and (char not in punct)])\r\n",
    "    sentence = sentence.lower()\r\n",
    "    sequence = nltk.word_tokenize(sentence)\r\n",
    "    # POS Tags ermitteln\r\n",
    "    sequence = nltk.pos_tag(sequence)\r\n",
    "    for word,pos in sequence:\r\n",
    "        if pos in ['NN','NNS','NNP','JJ','JJR','JJS','RB','RBR','RBS']:\r\n",
    "            unigram.append(word)\r\n",
    "    toktext.append(word)\r\n",
    "print(toktext)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# n-Grame erstellen \r\n",
    "bigram.extend(list(ngrams(unigram, 2)))\r\n",
    "trigram.extend(list(ngrams(unigram, 3)))\r\n",
    "fourgram.extend(list(ngrams(unigram, 4)))\r\n",
    "fivegram.extend(list(ngrams(unigram, 5)))\r\n",
    "sixgram.extend(list(ngrams(unigram, 6)))\r\n",
    "# tengram.extend(list(ngrams(unigram, 10)))\r\n",
    "\r\n",
    "def removal(x):\r\n",
    "    res = []\r\n",
    "    for pair in x:\r\n",
    "        count = 0\r\n",
    "        for word in pair:\r\n",
    "            if word in stop_words:\r\n",
    "                count = count or 0\r\n",
    "            else:\r\n",
    "                count = count or 1\r\n",
    "        if (count)==1:\r\n",
    "            res.append(pair)\r\n",
    "    return res\r\n",
    "\r\n",
    "bigram = removal(bigram)\r\n",
    "trigram = removal(trigram)\r\n",
    "fourgram = removal(fourgram)\r\n",
    "fourgram = removal(fivegram)\r\n",
    "fourgram = removal(sixgram)\r\n",
    "# tengram = removal(tengram)\r\n",
    "\r\n",
    "freq_bi = nltk.FreqDist(bigram)\r\n",
    "freq_tri = nltk.FreqDist(trigram)\r\n",
    "freq_four = nltk.FreqDist(fourgram)\r\n",
    "freq_five = nltk.FreqDist(fivegram)\r\n",
    "freq_six = nltk.FreqDist(sixgram)\r\n",
    "# freq_ten = nltk.FreqDist(tengram)\r\n",
    "\r\n",
    "print('freq_bi',freq_bi.most_common(20),'\\n')\r\n",
    "print('freq_tri',freq_tri.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_four.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_five.most_common(20),'\\n')\r\n",
    "print('freq_four',freq_six.most_common(20),'\\n')\r\n",
    "# print('freq_ten',freq_ten.most_common(20),'\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "freq_bi [(('harry', 'd'), 89), (('d', 'never'), 50), (('harry', 'never'), 32), (('harry', 'more'), 30), (('much', 'more'), 30), (('more', 'harry'), 30), (('never', 'harry'), 29), (('harry', 'potter'), 29), (('death', 'eater'), 29), (('harry', 'not'), 28), (('harry', 's'), 27), (('ron', 'hermione'), 23), (('harry', 'hermione'), 23), (('even', 'more'), 21), (('harry', 'ho'), 20), (('mr', 'weasley'), 20), (('i', 'harry'), 19), (('i', 'never'), 18), (('mrs', 'weasley'), 17), (('harry', 'wand'), 16)] \n",
      "\n",
      "freq_tri [(('harry', 'd', 'never'), 28), (('harry', 'd', 'ron'), 8), (('defence', 'dark', 'arts'), 6), (('once', 'more', 'harry'), 5), (('harry', 'd', 'ever'), 5), (('harry', 'd', 'hermione'), 5), (('more', 'death', 'eater'), 5), (('d', 'never', 'life'), 4), (('never', 'anything', 'so'), 4), (('more', 'cheerful', 'harry'), 4), (('never', 'so', 'much'), 4), (('next', 'few', 'days'), 4), (('never', 'ron', 'hermione'), 4), (('harry', 'once', 'more'), 4), (('slightly', 'more', 'cheerful'), 4), (('harry', 'd', 'not'), 4), (('harry', 'ho', 'more'), 4), (('more', 'anything', 'else'), 3), (('more', 'important', 'things'), 3), (('d', 'never', 'harry'), 3)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'more', 'dark', 'witches', 'wizards'), 2), (('house', 'more', 'dark', 'witches', 'wizards', 'other'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'mr', 'weasley', 'stairs'), 2), (('enough', 'anti\\u200bjinx', 'mr', 'weasley', 'stairs', 'not'), 2), (('anti\\u200bjinx', 'mr', 'weasley', 'stairs', 'not', 'so'), 2), (('mr', 'weasley', 'stairs', 'not', 'so', 'much'), 2), (('weasley', 'stairs', 'not', 'so', 'much', 'damage'), 2), (('stairs', 'not', 'so', 'much', 'damage', 'more'), 2), (('not', 'so', 'much', 'damage', 'more', 'attitude'), 2), (('so', 'much', 'damage', 'more', 'attitude', 'vandalism'), 2), (('much', 'damage', 'more', 'attitude', 'vandalism', 'harry'), 2), (('damage', 'more', 'attitude', 'vandalism', 'harry', 'wizards'), 2), (('more', 'attitude', 'vandalism', 'harry', 'wizards', 'funny'), 2), (('attitude', 'vandalism', 'harry', 'wizards', 'funny', 'expression'), 2), (('vandalism', 'harry', 'wizards', 'funny', 'expression', 'something'), 2), (('harry', 'wizards', 'funny', 'expression', 'something', 'much'), 2), (('wizards', 'funny', 'expression', 'something', 'much', 'deeper'), 2), (('funny', 'expression', 'something', 'much', 'deeper', 'nastier'), 2), (('expression', 'something', 'much', 'deeper', 'nastier', 'mr'), 2), (('something', 'much', 'deeper', 'nastier', 'mr', 'weasley'), 2)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'more', 'dark', 'witches'), 2), (('house', 'more', 'dark', 'witches', 'wizards'), 2), (('more', 'dark', 'witches', 'wizards', 'other'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'mr', 'weasley'), 2), (('enough', 'anti\\u200bjinx', 'mr', 'weasley', 'stairs'), 2), (('anti\\u200bjinx', 'mr', 'weasley', 'stairs', 'not'), 2), (('mr', 'weasley', 'stairs', 'not', 'so'), 2), (('weasley', 'stairs', 'not', 'so', 'much'), 2), (('stairs', 'not', 'so', 'much', 'damage'), 2), (('not', 'so', 'much', 'damage', 'more'), 2), (('so', 'much', 'damage', 'more', 'attitude'), 2), (('much', 'damage', 'more', 'attitude', 'vandalism'), 2), (('damage', 'more', 'attitude', 'vandalism', 'harry'), 2), (('more', 'attitude', 'vandalism', 'harry', 'wizards'), 2), (('attitude', 'vandalism', 'harry', 'wizards', 'funny'), 2), (('vandalism', 'harry', 'wizards', 'funny', 'expression'), 2), (('harry', 'wizards', 'funny', 'expression', 'something'), 2), (('wizards', 'funny', 'expression', 'something', 'much'), 2), (('funny', 'expression', 'something', 'much', 'deeper'), 2), (('expression', 'something', 'much', 'deeper', 'nastier'), 2)] \n",
      "\n",
      "freq_four [(('slytherin', 'house', 'more', 'dark', 'witches', 'wizards'), 2), (('house', 'more', 'dark', 'witches', 'wizards', 'other'), 2), (('simple', 'enough', 'anti\\u200bjinx', 'mr', 'weasley', 'stairs'), 2), (('enough', 'anti\\u200bjinx', 'mr', 'weasley', 'stairs', 'not'), 2), (('anti\\u200bjinx', 'mr', 'weasley', 'stairs', 'not', 'so'), 2), (('mr', 'weasley', 'stairs', 'not', 'so', 'much'), 2), (('weasley', 'stairs', 'not', 'so', 'much', 'damage'), 2), (('stairs', 'not', 'so', 'much', 'damage', 'more'), 2), (('not', 'so', 'much', 'damage', 'more', 'attitude'), 2), (('so', 'much', 'damage', 'more', 'attitude', 'vandalism'), 2), (('much', 'damage', 'more', 'attitude', 'vandalism', 'harry'), 2), (('damage', 'more', 'attitude', 'vandalism', 'harry', 'wizards'), 2), (('more', 'attitude', 'vandalism', 'harry', 'wizards', 'funny'), 2), (('attitude', 'vandalism', 'harry', 'wizards', 'funny', 'expression'), 2), (('vandalism', 'harry', 'wizards', 'funny', 'expression', 'something'), 2), (('harry', 'wizards', 'funny', 'expression', 'something', 'much'), 2), (('wizards', 'funny', 'expression', 'something', 'much', 'deeper'), 2), (('funny', 'expression', 'something', 'much', 'deeper', 'nastier'), 2), (('expression', 'something', 'much', 'deeper', 'nastier', 'mr'), 2), (('something', 'much', 'deeper', 'nastier', 'mr', 'weasley'), 2)] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}