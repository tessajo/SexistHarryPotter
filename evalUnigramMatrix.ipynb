{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalFunctions as ef\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pathlist = []\n",
    "for i in range(0,7):\n",
    "    filename_source = 'sentenceswithnames'+str(i)+'.txt'\n",
    "    filepath_source = os.path.join('Data','RESULTS',filename_source)\n",
    "    filename_target = 'unigram_mtx'+str(i)+'.txt'\n",
    "    filepath_target = os.path.join('Data','RESULTS',filename_target)\n",
    "    pathlist.append(filepath_target)  \n",
    "    if not os.path.exists(filepath_target):\n",
    "        print('not exists')\n",
    "        # Statistischee Analysen gesamter Text\n",
    "        with open(filepath_source,'r',encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        # Sätze erstellen\n",
    "        sents = nltk.sent_tokenize(content) # Output is a list of sentences\n",
    "        print(len(sents))\n",
    "        # print(type(sents))\n",
    "        # print(sents)\n",
    "        unigrammtx = ef.unigramMatrix(sents)\n",
    "        print(len(unigrammtx))\n",
    "        with open(filepath_target,'w',encoding='utf-8') as f:\n",
    "            for word in unigrammtx:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "\n",
    "filepath_master = os.path.join('Data','RESULTS','unigram_mtx.txt')\n",
    "# if os.path.exists(filepath_master):\n",
    "if not os.path.exists(filepath_master):\n",
    "    print(pathlist)\n",
    "    with open(filepath_master,'a') as f:\n",
    "        for filepath in pathlist:\n",
    "            with open(filepath,'r') as input:\n",
    "                f.write(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630316\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Data','RESULTS','unigram_mtx.txt'),'r',encoding='utf-8') as f:\n",
    "    content = f.readlines() #.replace('\\n','')\n",
    "ngram_mtx = []\n",
    "for line in content:\n",
    "    ngram_mtx.append(line.replace('\\n',''))\n",
    "\n",
    "print(len(ngram_mtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Filter auf die Unigramme\n",
    "uallmtx = ef.ngramFilter(ngram_mtx)\n",
    "\n",
    "print(type(uallmtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uallmtx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ngramme initialisieren\n",
    "# print('unimtx')\n",
    "# unimtx_freq,mtx_bigram = ef.initNgrams(unigrammtx)\n",
    "print('uallmtx')\n",
    "uall_fmtxreq,uallmtx_bigram = ef.initNgrams(uallmtx)\n",
    "# print('unamesmtx')\n",
    "# unamesmtx_freq,unamesmtx_bigram = ef.initNgrams(unamesmtx)\n",
    "# print('uadmtx')\n",
    "# uadmtx_freq,uadmtx_bigram = ef.initNgrams(uadmtx)\n",
    "\n",
    "\n",
    "# print(uallmtx_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len connection\n",
      "7199\n"
     ]
    }
   ],
   "source": [
    "def createNetworkGraph(bigram):\n",
    "    # print('len bigram')\n",
    "    # print(len(bigram))\n",
    "    \n",
    "    # Gewichtung\n",
    "    weight = {}\n",
    "    # Tuple-Dictionaries\n",
    "    connection = {}\n",
    "    connection_f = {}\n",
    "    connection_m = {}\n",
    "    # Filter values\n",
    "    fv_names, fv_adv, fv_adj, female, male, res = ef.getFilterValues(1,0,0,1,1) # funktionuggelt\n",
    "    # print(fv_names) # funktionuggelt\n",
    "    # Graphen\n",
    "    g = nx.Graph()\n",
    "    g_f = nx.Graph()\n",
    "    g_m = nx.Graph()\n",
    "    # Kennzahlen\n",
    "    weight_of_nodes = []\n",
    "    # Farben Variablen\n",
    "    lblue = '#85B4E4'\n",
    "    dgreen = '#0F8436'\n",
    "    for tuple in bigram:\n",
    "        weight = 0\n",
    "        # print('1')\n",
    "        # print(tuple[0])\n",
    "        # print('2')\n",
    "        # print(tuple[1])\n",
    "        # TODO Gewichtung überprüfen\n",
    "        # TODO Graphen umstrukturieren\n",
    "        if tuple[0] in fv_names and not tuple[1] in fv_names:\n",
    "            # print('criteria met')\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                connection_f.update({tuple:weight})\n",
    "                weight = connection_f.get(tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                connection_m.update({tuple:weight})\n",
    "                weight = connection_m.get(tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({tuple:weight})\n",
    "            # allgemein\n",
    "            # print(connection)\n",
    "            connection.update({tuple:weight})\n",
    "            weight = connection.get(tuple)\n",
    "            weight += 1\n",
    "            connection.update({tuple:weight})\n",
    "        if tuple[1] in fv_names and not tuple[0] in fv_names:\n",
    "            # print('criteria met')\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_f.update({n_tuple:weight})\n",
    "                weight = connection_f.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({n_tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_m.update({n_tuple:weight})\n",
    "                weight = connection_m.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({n_tuple:weight})\n",
    "            # allgemein\n",
    "            n_tuple = (tuple[1],tuple[0])\n",
    "            connection.update({n_tuple:weight})\n",
    "            weight = connection.get(n_tuple)\n",
    "            weight += 1\n",
    "            connection.update({n_tuple:weight})\n",
    "    print('len connection')\n",
    "    print(len(connection))\n",
    "    # Alle Personen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    for key in connection:\n",
    "        value = connection.get(key)\n",
    "        g.add_node(key[0], cluster='noun')\n",
    "        g.add_node(key[1], cluster='ad')\n",
    "        g.add_edge(key[1],key[0],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # Reciprocity(undirected)\n",
    "    rec = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc = nx.average_node_connectivity(g)\n",
    "    ec = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique = nx.find_cliques(g)\n",
    "    n_clique = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac}\\nReciprocity: {rec}\\n\"\n",
    "    title += f\"Attribut-Assortivität-Koeffizient: {aac}\\nGrad-Assortivität-Koeffizient: {dac}\\n\"\n",
    "    title += f\"Durchschnitts-Nachbargrad: {andeg}\\nGeneralized Degree: {gdeg}\\n\"\n",
    "    title += f\"Diameter: {dia}\\nEccentricity: {ecc}\\n\"\n",
    "    title += f\"Average Node-Connectivity: {anc}\\nAverage Edge-Connectivity{ec}\\n\"\n",
    "    title += f\"Clique: {clique}\\nAnzahl an Cliquen: {n_clique}\"\n",
    "    # Kennzahlen und Algos\n",
    "    # print(weight_of_nodes)\n",
    "    # Graphen darstellen\n",
    "    fig = plt.figure(figsize=(50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(title)\n",
    "    # plt.savefig('wordconnectivity_all.png')\n",
    "    # Frauen-Graph    \n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_f:\n",
    "        value = connection_f.get(key)\n",
    "        g_f.add_node(key[0], cluster='noun')\n",
    "        g_f.add_node(key[1], cluster='ad')\n",
    "        g_f.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # Reciprocity(undirected)\n",
    "    rec_f = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac_f = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac_f = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg_f = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg_f = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia_f = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc_f = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc_f = nx.average_node_connectivity(g)\n",
    "    ec_f = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique_f = nx.find_cliques(g)\n",
    "    n_clique_f = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title_f = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac_f}\\nReciprocity: {rec_f}\\n\"\n",
    "    title_f += f\"Attribut-Assortivität-Koeffizient: {aac_f}\\nGrad-Assortivität-Koeffizient: {dac_f}\\n\"\n",
    "    title_f += f\"Durchschnitts-Nachbargrad: {andeg_f}\\nGeneralized Degree: {gdeg_f}\\n\"\n",
    "    title_f += f\"Diameter: {dia_f}\\nEccentricity: {ecc_f}\\n\"\n",
    "    title_f += f\"Average Node-Connectivity: {anc_f}\\nAverage Edge-Connectivity{ec_f}\\n\"\n",
    "    title_f += f\"Clique: {clique_f}\\nAnzahl an Cliquen: {n_clique_f}\"\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_f, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(title_f)\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Männer-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_m:\n",
    "        value = connection_m.get(key)\n",
    "        g_m.add_node(key[0], cluster='noun', color='red')\n",
    "        g_m.add_node(key[1], cluster='ad', color='red')\n",
    "        g_m.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "    # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # Reciprocity(undirected)\n",
    "    rec_m = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac_m = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac_m = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg_m = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg_m = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia_m = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc_m = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc_m = nx.average_node_connectivity(g)\n",
    "    ec_m = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique_m = nx.find_cliques(g)\n",
    "    n_clique_m = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title_m = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac_m}\\nReciprocity: {rec_m}\\n\"\n",
    "    title_m += f\"Attribut-Assortivität-Koeffizient: {aac_m}\\nGrad-Assortivität-Koeffizient: {dac_m}\\n\"\n",
    "    title_m += f\"Durchschnitts-Nachbargrad: {andeg_m}\\nGeneralized Degree: {gdeg_m}\\n\"\n",
    "    title_m += f\"Diameter: {dia_m}\\nEccentricity: {ecc_m}\\n\"\n",
    "    title_m += f\"Average Node-Connectivity: {anc_m}\\nAverage Edge-Connectivity{ec_m}\\n\"\n",
    "    title_m += f\"Clique: {clique_m}\\nAnzahl an Cliquen: {n_clique_m}\"\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_m, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(title_m)\n",
    "    # plt.savefig('wordconnectivity_men.png')\n",
    " \n",
    "\n",
    "# wordnet = nltk.pywordnet()\n",
    "\n",
    "createNetworkGraph(uallmtx_bigram)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
