{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalFunctions as ef\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pathlist = []\n",
    "for i in range(0,7):\n",
    "    filename_source = 'sentenceswithnames'+str(i)+'.txt'\n",
    "    filepath_source = os.path.join('Data','RESULTS',filename_source)\n",
    "    filename_target = 'unigram_mtx'+str(i)+'.txt'\n",
    "    filepath_target = os.path.join('Data','RESULTS',filename_target)\n",
    "    pathlist.append(filepath_target)  \n",
    "    if not os.path.exists(filepath_target):\n",
    "        print('not exists')\n",
    "        # Statistischee Analysen gesamter Text\n",
    "        with open(filepath_source,'r',encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        # Sätze erstellen\n",
    "        sents = nltk.sent_tokenize(content) # Output is a list of sentences\n",
    "        print(len(sents))\n",
    "        # print(type(sents))\n",
    "        # print(sents)\n",
    "        unigrammtx = ef.unigramMatrix(sents)\n",
    "        print(len(unigrammtx))\n",
    "        with open(filepath_target,'w',encoding='utf-8') as f:\n",
    "            for word in unigrammtx:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "\n",
    "filepath_master = os.path.join('Data','RESULTS','unigram_mtx.txt')\n",
    "# if os.path.exists(filepath_master):\n",
    "if not os.path.exists(filepath_master):\n",
    "    print(pathlist)\n",
    "    with open(filepath_master,'a') as f:\n",
    "        for filepath in pathlist:\n",
    "            with open(filepath,'r') as input:\n",
    "                f.write(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630316\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Data','RESULTS','unigram_mtx.txt'),'r',encoding='utf-8') as f:\n",
    "    content = f.readlines() #.replace('\\n','')\n",
    "ngram_mtx = []\n",
    "for line in content:\n",
    "    ngram_mtx.append(line.replace('\\n',''))\n",
    "\n",
    "print(len(ngram_mtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Filter auf die Unigramme\n",
    "uallmtx = ef.ngramFilter(ngram_mtx)\n",
    "\n",
    "print(type(uallmtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uallmtx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ngramme initialisieren\n",
    "# print('unimtx')\n",
    "# unimtx_freq,mtx_bigram = ef.initNgrams(unigrammtx)\n",
    "print('uallmtx')\n",
    "uall_fmtxreq,uallmtx_bigram = ef.initNgrams(uallmtx)\n",
    "# print('unamesmtx')\n",
    "# unamesmtx_freq,unamesmtx_bigram = ef.initNgrams(unamesmtx)\n",
    "# print('uadmtx')\n",
    "# uadmtx_freq,uadmtx_bigram = ef.initNgrams(uadmtx)\n",
    "\n",
    "\n",
    "# print(uallmtx_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len connection\n",
      "7199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4166465/353704587.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;31m# wordnet = nltk.pywordnet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m \u001b[0mcreateNetworkGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muallmtx_bigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4166465/353704587.py\u001b[0m in \u001b[0;36mcreateNetworkGraph\u001b[0;34m(bigram)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mecc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meccentricity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Average Node-Connectivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0manc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_node_connectivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_connectivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# Cliques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/algorithms/connectivity/connectivity.py\u001b[0m in \u001b[0;36maverage_node_connectivity\u001b[0;34m(G, flow_func)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mnum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlocal_node_connectivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mden\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/algorithms/connectivity/connectivity.py\u001b[0m in \u001b[0;36mlocal_node_connectivity\u001b[0;34m(G, s, t, flow_func, auxiliary, residual, cutoff)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cutoff\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum_flow_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{mapping[s]}B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{mapping[t]}A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/algorithms/flow/maxflow.py\u001b[0m in \u001b[0;36mmaximum_flow_value\u001b[0;34m(flowG, _s, _t, capacity, flow_func, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flow_func has to be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflowG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"flow_value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/algorithms/flow/edmondskarp.py\u001b[0m in \u001b[0;36medmonds_karp\u001b[0;34m(G, s, t, capacity, residual, value_only, cutoff)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medmonds_karp_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"algorithm\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"edmonds_karp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/algorithms/flow/edmondskarp.py\u001b[0m in \u001b[0;36medmonds_karp_impl\u001b[0;34m(G, s, t, capacity, residual, cutoff)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Initialize/reset the residual network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"flow\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mAtlasView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_for_adding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mdirected\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mholds\u001b[0m \u001b[0moutgoing\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuccessor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAdjacencyView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/networkx/classes/coreviews.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_atlas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atlas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def createNetworkGraph(bigram):\n",
    "    # print('len bigram')\n",
    "    # print(len(bigram))\n",
    "    \n",
    "    # Gewichtung\n",
    "    weight = {}\n",
    "    # Tuple-Dictionaries\n",
    "    connection = {}\n",
    "    connection_f = {}\n",
    "    connection_m = {}\n",
    "    # Filter values\n",
    "    fv_names, fv_adv, fv_adj, female, male, res = ef.getFilterValues(1,0,0,1,1) # funktionuggelt\n",
    "    # print(fv_names) # funktionuggelt\n",
    "    # Graphen\n",
    "    g = nx.Graph()\n",
    "    g_f = nx.Graph()\n",
    "    g_m = nx.Graph()\n",
    "    # Kennzahlen\n",
    "    weight_of_nodes = []\n",
    "    # Farben Variablen\n",
    "    lblue = '#85B4E4'\n",
    "    dgreen = '#0F8436'\n",
    "    for tuple in bigram:\n",
    "        weight = 0\n",
    "        # print('1')\n",
    "        # print(tuple[0])\n",
    "        # print('2')\n",
    "        # print(tuple[1])\n",
    "        # TODO Gewichtung überprüfen\n",
    "        # TODO Graphen umstrukturieren\n",
    "        if tuple[0] in fv_names and not tuple[1] in fv_names:\n",
    "            # print('criteria met')\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                connection_f.update({tuple:weight})\n",
    "                weight = connection_f.get(tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                connection_m.update({tuple:weight})\n",
    "                weight = connection_m.get(tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({tuple:weight})\n",
    "            # allgemein\n",
    "            # print(connection)\n",
    "            connection.update({tuple:weight})\n",
    "            weight = connection.get(tuple)\n",
    "            weight += 1\n",
    "            connection.update({tuple:weight})\n",
    "        if tuple[1] in fv_names and not tuple[0] in fv_names:\n",
    "            # print('criteria met')\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_f.update({n_tuple:weight})\n",
    "                weight = connection_f.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({n_tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_m.update({n_tuple:weight})\n",
    "                weight = connection_m.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({n_tuple:weight})\n",
    "            # allgemein\n",
    "            n_tuple = (tuple[1],tuple[0])\n",
    "            connection.update({n_tuple:weight})\n",
    "            weight = connection.get(n_tuple)\n",
    "            weight += 1\n",
    "            connection.update({n_tuple:weight})\n",
    "    print('len connection')\n",
    "    print(len(connection))\n",
    "    # Alle Personen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    for key in connection:\n",
    "        value = connection.get(key)\n",
    "        g.add_node(key[0], cluster='noun')\n",
    "        g.add_node(key[1], cluster='ad')\n",
    "        g.add_edge(key[1],key[0],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    '''\n",
    "    # Reciprocity(undirected)\n",
    "    rec = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc = nx.average_node_connectivity(g)\n",
    "    ec = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique = nx.find_cliques(g)\n",
    "    n_clique = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac}\\nReciprocity: {rec}\\n\"\n",
    "    title += f\"Attribut-Assortivität-Koeffizient: {aac}\\nGrad-Assortivität-Koeffizient: {dac}\\n\"\n",
    "    title += f\"Durchschnitts-Nachbargrad: {andeg}\\nGeneralized Degree: {gdeg}\\n\"\n",
    "    title += f\"Diameter: {dia}\\nEccentricity: {ecc}\\n\"\n",
    "    title += f\"Average Node-Connectivity: {anc}\\nAverage Edge-Connectivity{ec}\\n\"\n",
    "    title += f\"Clique: {clique}\\nAnzahl an Cliquen: {n_clique}\"\n",
    "    '''\n",
    "    # Kennzahlen und Algos\n",
    "    # print(weight_of_nodes)\n",
    "    # Graphen darstellen\n",
    "    fig = plt.figure(figsize=(50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title('Wortverknüpfungen aller Personen')\n",
    "    # plt.savefig('wordconnectivity_all.png')\n",
    "    # Frauen-Graph    \n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_f:\n",
    "        value = connection_f.get(key)\n",
    "        g_f.add_node(key[0], cluster='noun')\n",
    "        g_f.add_node(key[1], cluster='ad')\n",
    "        g_f.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    '''\n",
    "    # Reciprocity(undirected)\n",
    "    rec_f = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac_f = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac_f = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg_f = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg_f = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia_f = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc_f = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc_f = nx.average_node_connectivity(g)\n",
    "    ec_f = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique_f = nx.find_cliques(g)\n",
    "    n_clique_f = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title_f = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac_f}\\nReciprocity: {rec_f}\\n\"\n",
    "    title_f += f\"Attribut-Assortivität-Koeffizient: {aac_f}\\nGrad-Assortivität-Koeffizient: {dac_f}\\n\"\n",
    "    title_f += f\"Durchschnitts-Nachbargrad: {andeg_f}\\nGeneralized Degree: {gdeg_f}\\n\"\n",
    "    title_f += f\"Diameter: {dia_f}\\nEccentricity: {ecc_f}\\n\"\n",
    "    title_f += f\"Average Node-Connectivity: {anc_f}\\nAverage Edge-Connectivity{ec_f}\\n\"\n",
    "    title_f += f\"Clique: {clique_f}\\nAnzahl an Cliquen: {n_clique_f}\"\n",
    "    '''\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_f, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title('Wortverknüpfungen aller weiblichen Personen')\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Männer-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_m:\n",
    "        value = connection_m.get(key)\n",
    "        g_m.add_node(key[0], cluster='noun', color='red')\n",
    "        g_m.add_node(key[1], cluster='ad', color='red')\n",
    "        g_m.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "    # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    '''\n",
    "    # Reciprocity(undirected)\n",
    "    rec_m = nx.overall_reciprocity(g)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac_m = nx.attribute_assortativity_coefficient(g,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac_m = nx.degree_assortativity_coefficient(g)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg_m = nx.average_neighbor_degree(g)\n",
    "    # Generalized Degree\n",
    "    gdeg_m = nx.generalized_degree(g)\n",
    "    # Diameter\n",
    "    dia_m = nx.diameter(g)\n",
    "    # Eccentricity\n",
    "    ecc_m = nx.eccentricity(g)\n",
    "    # Average Node-Connectivity\n",
    "    anc_m = nx.average_node_connectivity(g)\n",
    "    ec_m = nx.edge_connectivity(g)\n",
    "    # Cliques\n",
    "    clique_m = nx.find_cliques(g)\n",
    "    n_clique_m = nx.graph_number_of_cliques(g)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(g)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(g)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(g)\n",
    "    title_m = f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {aac_m}\\nReciprocity: {rec_m}\\n\"\n",
    "    title_m += f\"Attribut-Assortivität-Koeffizient: {aac_m}\\nGrad-Assortivität-Koeffizient: {dac_m}\\n\"\n",
    "    title_m += f\"Durchschnitts-Nachbargrad: {andeg_m}\\nGeneralized Degree: {gdeg_m}\\n\"\n",
    "    title_m += f\"Diameter: {dia_m}\\nEccentricity: {ecc_m}\\n\"\n",
    "    title_m += f\"Average Node-Connectivity: {anc_m}\\nAverage Edge-Connectivity{ec_m}\\n\"\n",
    "    title_m += f\"Clique: {clique_m}\\nAnzahl an Cliquen: {n_clique_m}\"\n",
    "    '''\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_m, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title('Wortverknüpfungen aller männlichen Personen')\n",
    "    # plt.savefig('wordconnectivity_men.png')\n",
    "    return g, g_f, g_m\n",
    " \n",
    "def calcGraphMetrics(graph):\n",
    "    # Reciprocity(undirected)\n",
    "    rec = nx.overall_reciprocity(graph)\n",
    "    # Attribut-Assortivität-Koeffizient\n",
    "    aac = nx.attribute_assortativity_coefficient(graph,\"cluster\")\n",
    "    # Grad-Assortivität-Koeffizient\n",
    "    dac = nx.degree_assortativity_coefficient(graph)\n",
    "    # Durchschnitts-Nachbargrad\n",
    "    andeg = nx.average_neighbor_degree(graph)\n",
    "    # Generalized Degree\n",
    "    gdeg = nx.generalized_degree(graph)\n",
    "    # Diameter\n",
    "    dia = nx.diameter(graph)\n",
    "    # Eccentricity\n",
    "    ecc = nx.eccentricity(graph)\n",
    "    # Average Node-Connectivity\n",
    "    anc = nx.average_node_connectivity(graph)\n",
    "    ec = nx.edge_connectivity(graph)\n",
    "    # Cliques\n",
    "    clique = nx.find_cliques(graph)\n",
    "    n_clique = nx.graph_number_of_cliques(graph)\n",
    "    # # Transitivity\n",
    "    # trans = nx.transitivity(graph)\n",
    "    # # Clustering\n",
    "    # clu = nx.clustering(graph)\n",
    "    # # Average Clustering\n",
    "    # avgcluster = nx.average_clustering(graph)\n",
    "    print(f'Assortivitätskoeffizient: {aac_m}')\n",
    "    print(f'Reciprocity: {rec_m}')\n",
    "    print(f'Attribut-Assortivität-Koeffizient: {aac_m}')\n",
    "    print(f'Grad-Assortivität-Koeffizient: {dac_m}')\n",
    "    print(f'Durchschnitts-Nachbargrad: {andeg_m}')\n",
    "    print(f'Generalized Degree: {gdeg_m}')\n",
    "    print(f'Diameter: {dia_m}')\n",
    "    print(f'Eccentricity: {ecc_m}')\n",
    "    print(f'Average Node-Connectivity: {anc_m}')\n",
    "    print(f'Average Edge-Connectivity{ec_m}')\n",
    "    print(f'Clique: {clique_m}')\n",
    "    print(f'Anzahl an Cliquen: {n_clique_m}')\n",
    "\n",
    "\n",
    "# wordnet = nltk.pywordnet()\n",
    "\n",
    "graph_all, graph_female, graph_male = createNetworkGraph(uallmtx_bigram)\n",
    "\n",
    "calcGraphMetrics(graph_all)\n",
    "calcGraphMetrics(graph_female)\n",
    "calcGraphMetrics(graph_male)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
