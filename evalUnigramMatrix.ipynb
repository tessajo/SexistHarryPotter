{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalFunctions as ef\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data/RESULTS/unigram_mtx0.txt', 'Data/RESULTS/unigram_mtx1.txt', 'Data/RESULTS/unigram_mtx2.txt', 'Data/RESULTS/unigram_mtx3.txt', 'Data/RESULTS/unigram_mtx4.txt', 'Data/RESULTS/unigram_mtx5.txt', 'Data/RESULTS/unigram_mtx6.txt']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pathlist = []\n",
    "for i in range(0,7):\n",
    "    filename_source = 'sentenceswithnames'+str(i)+'.txt'\n",
    "    filepath_source = os.path.join('Data','RESULTS',filename_source)\n",
    "    filename_target = 'unigram_mtx'+str(i)+'.txt'\n",
    "    filepath_target = os.path.join('Data','RESULTS',filename_target)\n",
    "    pathlist.append(filepath_target)  \n",
    "    if not os.path.exists(filepath_target):\n",
    "        # Statistischee Analysen gesamter Text\n",
    "        with open(filepath_source,'r',encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        # Sätze erstellen\n",
    "        sents = nltk.sent_tokenize(content) # Output is a list of sentences\n",
    "        print(len(sents))\n",
    "        # print(type(sents))\n",
    "        # print(sents)\n",
    "        unigrammtx = ef.unigramMatrix(sents)\n",
    "        print(len(unigrammtx))\n",
    "        with open(filepath_target,'w',encoding='utf-8') as f:\n",
    "            for word in unigrammtx:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "\n",
    "filepath_master = os.path.join('Data','RESULTS','unigram_mtx.txt')\n",
    "if os.path.exists(filepath_master):\n",
    "    os.remove(filepath_master)\n",
    "print(pathlist)\n",
    "with open(filepath_master,'a') as f:\n",
    "    for filepath in pathlist:\n",
    "        with open(filepath,'r') as input:\n",
    "            f.write(input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630316\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Data','RESULTS','unigram_mtx.txt'),'r',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "ngram_mtx = []\n",
    "for line in content:\n",
    "    ngram_mtx.append(line)\n",
    "\n",
    "print(len(ngram_mtx))\n",
    "# Filter auf die Unigramme\n",
    "uallmtx = ef.ngramFilter(ngram_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uallmtx\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2708318/3252355434.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# unimtx_freq,mtx_bigram = ef.initNgrams(unigrammtx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uallmtx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muall_fmtxreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muallmtx_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitNgrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muallmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# print('unamesmtx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# unamesmtx_freq,unamesmtx_bigram = ef.initNgrams(unamesmtx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SexistHarryPotter/evalFunctions.py\u001b[0m in \u001b[0;36minitNgrams\u001b[0;34m(unigram)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# n-Grame erstellen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mbigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     '''trigram.extend(list(ngrams(unigram, 3)))\n\u001b[1;32m    120\u001b[0m     \u001b[0mfourgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nltk/util.py\u001b[0m in \u001b[0;36mngrams\u001b[0;34m(sequence, n, **kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \"\"\"\n\u001b[0;32m--> 862\u001b[0;31m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;31m# Creates the sliding window, of n no. of items.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/nltk/util.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequence, n, pad_left, pad_right, left_pad_symbol, right_pad_symbol)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \"\"\"\n\u001b[0;32m--> 815\u001b[0;31m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpad_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pad_symbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ngramme initialisieren\n",
    "# print('unimtx')\n",
    "# unimtx_freq,mtx_bigram = ef.initNgrams(unigrammtx)\n",
    "print('uallmtx')\n",
    "uall_fmtxreq,uallmtx_bigram = ef.initNgrams(uallmtx)\n",
    "# print('unamesmtx')\n",
    "# unamesmtx_freq,unamesmtx_bigram = ef.initNgrams(unamesmtx)\n",
    "# print('uadmtx')\n",
    "# uadmtx_freq,uadmtx_bigram = ef.initNgrams(uadmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uallmtx_bigram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2692160/449221261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# wordnet = nltk.pywordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0mcreateNetworkGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muallmtx_bigram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'uallmtx_bigram' is not defined"
     ]
    }
   ],
   "source": [
    "def createNetworkGraph(bigram):\n",
    "    # Gewichtung\n",
    "    weight = {}\n",
    "    # Tuple-Dictionaries\n",
    "    connection = {}\n",
    "    connection_f = {}\n",
    "    connection_m = {}\n",
    "    # Filter values\n",
    "    fv_names,fv_adv,fv_adj,female,male = ef.getFilterValues(1,0,0,1,1) # funktionuggelt\n",
    "    # Graphen\n",
    "    g = nx.Graph()\n",
    "    g_f = nx.Graph()\n",
    "    g_m = nx.Graph()\n",
    "    # Kennzahlen\n",
    "    weight_of_nodes = []\n",
    "    # Farben Variablen\n",
    "    lblue = '#85B4E4'\n",
    "    dgreen = '#0F8436'\n",
    "    for tuple in bigram:\n",
    "        weight = 0\n",
    "        # TODO Gewichtung überprüfen\n",
    "        # TODO Graphen umstrukturieren\n",
    "        if tuple[0] in fv_names and not tuple[1] in fv_names:\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                connection_f.update({tuple:weight})\n",
    "                weight = connection_f.get(tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                connection_m.update({tuple:weight})\n",
    "                weight = connection_m.get(tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({tuple:weight})\n",
    "            # allgemein\n",
    "            connection.update({tuple:weight})\n",
    "            weight = connection.get(tuple)\n",
    "            weight += 1\n",
    "            connection.update({tuple:weight})\n",
    "        if tuple[1] in fv_names and not tuple[0] in fv_names:\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_f.update({n_tuple:weight})\n",
    "                weight = connection_f.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({n_tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_m.update({n_tuple:weight})\n",
    "                weight = connection_m.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({n_tuple:weight})\n",
    "            # allgemein\n",
    "            n_tuple = (tuple[1],tuple[0])\n",
    "            connection.update({n_tuple:weight})\n",
    "            weight = connection.get(n_tuple)\n",
    "            weight += 1\n",
    "            connection.update({n_tuple:weight})\n",
    "    # Alle Personen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    for key in connection:\n",
    "        value = connection.get(key)\n",
    "        g.add_node(key[0], cluster='noun')\n",
    "        g.add_node(key[1], cluster='ad')\n",
    "        g.add_edge(key[1],key[0],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # Assortivität-Koeffizient\n",
    "    cr = nx.attribute_assortativity_coefficient(g,\"cluster\",nodes=key)\n",
    "    # Reciprocity\n",
    "    rec = nx.overall_reciprocity(g)\n",
    "    # Transitivity\n",
    "    trans = nx.transitivity(g)\n",
    "    # Clustering\n",
    "    clu = nx.clustering(g)\n",
    "    avgcluster = nx.average_clustering(g)\n",
    "    gdeg = nx.generalized_degree(g)\n",
    "    \n",
    "    print(cr, rec, clu, avgcluster, gdeg)\n",
    "    # Kennzahlen und Algos\n",
    "    # print(weight_of_nodes)\n",
    "    # Graphen darstellen\n",
    "    fig = plt.figure(figsize=(50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {cr}\\nReciprocity: {rec}\")\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Frauen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_f:\n",
    "        value = connection_f.get(key)\n",
    "        g_f.add_node(key[0], cluster='noun')\n",
    "        g_f.add_node(key[1], cluster='ad')\n",
    "        g_f.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # assortativity_coefficient\n",
    "    cr_f = nx.attribute_assortativity_coefficient(g_f,\"cluster\",nodes=key)\n",
    "    rec_f = nx.overall_reciprocity(g_f)\n",
    "    print(cr_f, rec_f)\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_f, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen der weiblichen Personen\\nAssortivitätskoeffizient: {cr_f}\\nReciprocity: {rec_f}\")\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Männer-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_m:\n",
    "        value = connection_m.get(key)\n",
    "        g_m.add_node(key[0], cluster='noun', color='red')\n",
    "        g_m.add_node(key[1], cluster='ad', color='red')\n",
    "        g_m.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "    # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # assortativity_coefficient\n",
    "    cr_m = nx.attribute_assortativity_coefficient(g_m,\"cluster\",nodes=key)\n",
    "    rec_m = nx.overall_reciprocity(g_m)\n",
    "    print(cr_m, rec_m)\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_m, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen der männlichen Personen\\nAssortivitätskoeffizient: {cr_m}\\nReciprocity: {rec_m}\")\n",
    "    # plt.savefig('wordconnectivity_men.png')\n",
    "\n",
    "# wordnet = nltk.pywordnet\n",
    "\n",
    "createNetworkGraph(uallmtx_bigram)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
