{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalFunctions as ef\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "# kommi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16217\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(0,7):\n",
    "    filename = 'sentenceswithnames'+str(i)+'.txt'\n",
    "    filepath = os.path.join('Data','RESULTS',filename)\n",
    "    pathlist.append(filepath)        \n",
    "    # Statistischee Analysen gesamter Text\n",
    "    with open(filepath,'r',encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    # Sätze erstellen\n",
    "    sents = nltk.sent_tokenize(content) # Output is a list of sentences\n",
    "    print(len(sents))\n",
    "    # print(type(sents))\n",
    "    # print(sents)\n",
    "    unigrammtx = ef.unigramMatrix(sents)\n",
    "    print(len(unigrammtx))\n",
    "    with open(os.path.join('Data','RESULTS','unigram_mtx_'+str(i)+'.txt'),'r',encoding='utf-8') as f:\n",
    "        f.write(unigrammtx)\n",
    "\n",
    "for file in pathlist:\n",
    "with open('unigram_mtx.txt','w') as f:\n",
    "    f.write(str(file)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter auf die Unigramme\n",
    "uallmtx, unamesmtx, uadmtx = ef.ngramFilter(unigrammtx,1,0,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ngramme initialisieren\n",
    "print('unimtx')\n",
    "unimtx_freq,mtx_bigram = ef.initNgrams(unigrammtx)\n",
    "# print('uallmtx')\n",
    "# uall_fmtxreq,uallmtx_bigram = ef.initNgrams(uallmtx)\n",
    "# print('unamesmtx')\n",
    "# unamesmtx_freq,unamesmtx_bigram = ef.initNgrams(unamesmtx)\n",
    "# print('uadmtx')\n",
    "# uadmtx_freq,uadmtx_bigram = ef.initNgrams(uadmtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNetworkGraph(bigram):\n",
    "    # Gewichtung\n",
    "    weight = {}\n",
    "    # Tuple-Dictionaries\n",
    "    connection = {}\n",
    "    connection_f = {}\n",
    "    connection_m = {}\n",
    "    # Filter values\n",
    "    fv_names,fv_adv,fv_adj,female,male = ef.getFilterValues(1,0,0,1,1) # funktionuggelt\n",
    "    # Graphen\n",
    "    g = nx.Graph()\n",
    "    g_f = nx.Graph()\n",
    "    g_m = nx.Graph()\n",
    "    # Kennzahlen\n",
    "    weight_of_nodes = []\n",
    "    # Farben Variablen\n",
    "    lblue = '#85B4E4'\n",
    "    dgreen = '#0F8436'\n",
    "    for tuple in bigram:\n",
    "        weight = 0\n",
    "        # TODO Gewichtung überprüfen\n",
    "        # TODO Graphen umstrukturieren\n",
    "        if tuple[0] in fv_names and not tuple[1] in fv_names:\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                connection_f.update({tuple:weight})\n",
    "                weight = connection_f.get(tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                connection_m.update({tuple:weight})\n",
    "                weight = connection_m.get(tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({tuple:weight})\n",
    "            # allgemein\n",
    "            connection.update({tuple:weight})\n",
    "            weight = connection.get(tuple)\n",
    "            weight += 1\n",
    "            connection.update({tuple:weight})\n",
    "        if tuple[1] in fv_names and not tuple[0] in fv_names:\n",
    "            # weiblich\n",
    "            if tuple[0] in female:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_f.update({n_tuple:weight})\n",
    "                weight = connection_f.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_f.update({n_tuple:weight})\n",
    "            # männlich\n",
    "            if tuple[0] in male:\n",
    "                n_tuple = (tuple[1],tuple[0])\n",
    "                connection_m.update({n_tuple:weight})\n",
    "                weight = connection_m.get(n_tuple)\n",
    "                weight += 1\n",
    "                connection_m.update({n_tuple:weight})\n",
    "            # allgemein\n",
    "            n_tuple = (tuple[1],tuple[0])\n",
    "            connection.update({n_tuple:weight})\n",
    "            weight = connection.get(n_tuple)\n",
    "            weight += 1\n",
    "            connection.update({n_tuple:weight})\n",
    "    # Alle Personen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    for key in connection:\n",
    "        value = connection.get(key)\n",
    "        g.add_node(key[0], cluster='noun')\n",
    "        g.add_node(key[1], cluster='ad')\n",
    "        g.add_edge(key[1],key[0],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # Assortivität-Koeffizient\n",
    "    cr = nx.attribute_assortativity_coefficient(g,\"cluster\",nodes=key)\n",
    "    # Reciprocity\n",
    "    rec = nx.overall_reciprocity(g)\n",
    "    # Transitivity\n",
    "    trans = nx.transitivity(g)\n",
    "    # Clustering\n",
    "    clu = nx.clustering(g)\n",
    "    avgcluster = nx.average_clustering(g)\n",
    "    gdeg = nx.generalized_degree(g)\n",
    "    \n",
    "    print(cr, rec, clu, avgcluster, gdeg)\n",
    "    # Kennzahlen und Algos\n",
    "    # print(weight_of_nodes)\n",
    "    # Graphen darstellen\n",
    "    fig = plt.figure(figsize=(50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen aller Personen\\nAssortivitätskoeffizient: {cr}\\nReciprocity: {rec}\")\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Frauen-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_f:\n",
    "        value = connection_f.get(key)\n",
    "        g_f.add_node(key[0], cluster='noun')\n",
    "        g_f.add_node(key[1], cluster='ad')\n",
    "        g_f.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "        # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen) # TODO Farbe ändern\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # assortativity_coefficient\n",
    "    cr_f = nx.attribute_assortativity_coefficient(g_f,\"cluster\",nodes=key)\n",
    "    rec_f = nx.overall_reciprocity(g_f)\n",
    "    print(cr_f, rec_f)\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_f, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen der weiblichen Personen\\nAssortivitätskoeffizient: {cr_f}\\nReciprocity: {rec_f}\")\n",
    "    # plt.savefig('wordconnectivity_women.png')\n",
    "    # Männer-Graph\n",
    "    color_map = []\n",
    "    l_of_names = []\n",
    "    l_of_words = []\n",
    "    weight_of_nodes = []\n",
    "    for key in connection_m:\n",
    "        value = connection_m.get(key)\n",
    "        g_m.add_node(key[0], cluster='noun', color='red')\n",
    "        g_m.add_node(key[1], cluster='ad', color='red')\n",
    "        g_m.add_edge(key[0],key[1],weight=value)\n",
    "        weight_of_nodes.append(value)\n",
    "    # Color-Mapping\n",
    "        if key[1] in fv_names: # Paar aus Namen\n",
    "            # Name 1 bereits erfasst?\n",
    "            if not key[0] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            # Name 2 bereits erfasst?\n",
    "            if not key[1] in l_of_names: # Wenn nein\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[1])\n",
    "        else: # nur 1 Name\n",
    "            if not key[0] in l_of_names:\n",
    "                color_map.append(dgreen)\n",
    "                l_of_names.append(key[0])\n",
    "            #Color-Mapping für alle anderen Wörter\n",
    "            if not key[1] in l_of_words: \n",
    "                color_map.append(lblue)\n",
    "                l_of_words.append(key[1])\n",
    "    # assortativity_coefficient\n",
    "    cr_m = nx.attribute_assortativity_coefficient(g_m,\"cluster\",nodes=key)\n",
    "    rec_m = nx.overall_reciprocity(g_m)\n",
    "    print(cr_m, rec_m)\n",
    "    # Kennzahlen & Algos\n",
    "    # print(weight_of_nodes)\n",
    "    fig = plt.figure(figsize= (50,20))\n",
    "    subax1 = plt.subplot(122)\n",
    "    nx.draw(g_m, node_color=color_map, edge_color ='grey', with_labels=True)\n",
    "    subax1.set_title(f\"Wortverknüpfungen der männlichen Personen\\nAssortivitätskoeffizient: {cr_m}\\nReciprocity: {rec_m}\")\n",
    "    # plt.savefig('wordconnectivity_men.png')\n",
    "\n",
    "# wordnet = nltk.pywordnet\n",
    "\n",
    "createNetworkGraph(uallmtx_bigram)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d3916f4a9f8bbe764819496dcbc51ff6063af5fca03b7fe0f93e0003d125b6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
